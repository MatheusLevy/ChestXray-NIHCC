{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3370,"status":"ok","timestamp":1624375186728,"user":{"displayName":"Geraldo Braz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtXqi3trku-rIuoH0xOWyRiWTOHzjF-3aMiSoqK0CZug5CIQfFtp6j1Cm-cF40EeBEIFwQFaLAJ8BPUps0xRoqFhDQ8cOVsNv7LIUChnyydRpTwpl2HlkpsZcAIKeuUfbohPt9Pi_5xok3cbvqGNAOARrAlJelD-bU2J1ZghmMFUykKyUgDXN8jTdApXHDT7IeXAZIjrOQGwYLLaOwQ94ueWkjc_nrF00_zmFdJ47SMHg7Y0nkHszZHr8fOFyTzecDyvDh8lRZ76r-pm1Tws-1xq4ei3YoRrhy2HbvzOL2R3o5i1ApWPL6Yvkc1cj_vsIWgWD7zJS-0H-tfye90BSuM_u-wnI2sqW9TyJ-xn6X1FIVwZXQP6PHOnkl4aZIVnNAnv8i7-rvQcePg_F5ipLrnreY0YcuDGwNts2eRkQWLfWBo7UH3Gbp_WJ3MUT0FMdF3zAXrFJBWBobo8lKycnXHOBf1Hrik_wx0k_omC-lRXEsz7ST-oy_BBT9Ev_zB3BAv8L-BgJp4NvVPkPzSANL0pyoBkMGliA90O1RMiKLj1mUtidyP0XsR8xgky0iFwCCtLgF9yAceqV7ibGpD3EY-gS4AayTFFdAqnZGbaNofg6sNN2ZDuHlXav4_3pCjNC_zvp5iPTvfBRfoKx0_qaDaabQBpw8ZemqUgLMf_aJ6whbZfxsP1Zu9Q6D8Hyaoht6vP7ZS1fXOR-Hj0kRGUCWoL4Bt2brXeLoz85LvcXW6VCWxdf9-n9_JPv4STvk1SV2oQ=s64","userId":"07309379484309223386"},"user_tz":180},"id":"F9cXQVGEUGzk","outputId":"a1990802-6094-4e1e-b102-6fd6a0a416be"},"outputs":[],"source":["!pip install -U segmentation-models"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9015,"status":"ok","timestamp":1624375200459,"user":{"displayName":"Geraldo Braz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtXqi3trku-rIuoH0xOWyRiWTOHzjF-3aMiSoqK0CZug5CIQfFtp6j1Cm-cF40EeBEIFwQFaLAJ8BPUps0xRoqFhDQ8cOVsNv7LIUChnyydRpTwpl2HlkpsZcAIKeuUfbohPt9Pi_5xok3cbvqGNAOARrAlJelD-bU2J1ZghmMFUykKyUgDXN8jTdApXHDT7IeXAZIjrOQGwYLLaOwQ94ueWkjc_nrF00_zmFdJ47SMHg7Y0nkHszZHr8fOFyTzecDyvDh8lRZ76r-pm1Tws-1xq4ei3YoRrhy2HbvzOL2R3o5i1ApWPL6Yvkc1cj_vsIWgWD7zJS-0H-tfye90BSuM_u-wnI2sqW9TyJ-xn6X1FIVwZXQP6PHOnkl4aZIVnNAnv8i7-rvQcePg_F5ipLrnreY0YcuDGwNts2eRkQWLfWBo7UH3Gbp_WJ3MUT0FMdF3zAXrFJBWBobo8lKycnXHOBf1Hrik_wx0k_omC-lRXEsz7ST-oy_BBT9Ev_zB3BAv8L-BgJp4NvVPkPzSANL0pyoBkMGliA90O1RMiKLj1mUtidyP0XsR8xgky0iFwCCtLgF9yAceqV7ibGpD3EY-gS4AayTFFdAqnZGbaNofg6sNN2ZDuHlXav4_3pCjNC_zvp5iPTvfBRfoKx0_qaDaabQBpw8ZemqUgLMf_aJ6whbZfxsP1Zu9Q6D8Hyaoht6vP7ZS1fXOR-Hj0kRGUCWoL4Bt2brXeLoz85LvcXW6VCWxdf9-n9_JPv4STvk1SV2oQ=s64","userId":"07309379484309223386"},"user_tz":180},"id":"IYoSfnHQZujq","outputId":"6b1ee0ef-ae6f-49e9-9061-3450096e86b5"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-01-31 14:14:51.104011: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-31 14:14:51.184789: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-01-31 14:14:51.208369: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-31 14:14:51.570836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lucas_araujo/miniconda3/envs/lucas_a/lib/python3.10/site-packages/cv2/../../lib64:\n","2024-01-31 14:14:51.570871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lucas_araujo/miniconda3/envs/lucas_a/lib/python3.10/site-packages/cv2/../../lib64:\n","2024-01-31 14:14:51.570875: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]},{"name":"stdout","output_type":"stream","text":["Segmentation Models: using `keras` framework.\n"]}],"source":["import cv2\n","import numpy as np\n","import os\n","from keras.callbacks import ModelCheckpoint\n","from segmentation_models import *\n","from segmentation_models.metrics import iou_score\n","import shutil\n","import pickle\n","\n","def load_data(train, train_gt, test, test_gt):\n","    X_train = np.load(train, allow_pickle = True)\n","    y_train = np.expand_dims(np.load(train_gt, allow_pickle = True), axis = -1)//255\n","    # print(y_train.shape)\n","    # y_train = to_categorical(y_train, 1)\n","    X_test = np.load(test, allow_pickle = True)\n","    y_test = np.expand_dims(np.load(test_gt, allow_pickle = True), axis = -1)//255\n","    # print(y_test.shape)\n","    # y_test = to_categorical((y_test, 1), dtype = 'boolean')\n","    return X_train, y_train, X_test, y_test"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1LfbcLtRk1lo"},"outputs":[],"source":["def resize_data(old_set, shape):\n","    (H, W) = shape\n","    old_shape = old_set.shape\n","    new_set = np.empty(shape = (old_shape[0], H, W, old_shape[3]))\n","    for i in range(old_set.shape[0]):\n","        new_set[i] = np.expand_dims(cv2.resize(old_set[i, :, :, 0], (W, H)), axis = -1)\n","    \n","    return new_set\n","\n","def resize_all(sets, shape):\n","    for i in range(len(sets)):\n","        sets[i] = resize_data(sets[i], shape)\n","\n","    return sets\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"h3hM8sMWiKru"},"outputs":[],"source":["\n","def dice_calc(im_1, im_2, empty_score=6.0):\n","    im1 = im_1 > .3#!= 0#.astype(np.bool)\n","    im2 = im_2 > .3#!= 0#.astype(np.bool)\n","\n","    if im1.shape != im2.shape:\n","        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n","\n","    im_sum = im1.sum() + im2.sum()\n","    if im_sum == 0:\n","        # print(\"empty\")\n","        return empty_score\n","\n","    # Compute dice_val coefficient\n","    intersection = np.logical_and(im1, im2)\n","\n","    return 2. * intersection.sum() / im_sum\n","\n","def sensi_speci_accu(truth, mask):\n","\t# (TP + TN)/(TP + TN + FP + FN)\n","\t# TPR = TP / (TP + FN)\n","\t# SPC = TN / (FP + TN)\n","\n","    thresh = .3\n","    C = (((mask > thresh)*2 + (truth > thresh)).reshape(-1, 1) == range(4)).sum(0)\n","\n","    # sensitivity = C[3]/C[1::2].sum()\n","    # specificity = C[0]/C[::2].sum()\n","\n","    sensitivity = C[3]/np.sum(C[1] + C[3])\n","    specificity = C[0]/np.sum(C[0] + C[2])\n","    accuracy = (C[0] + C[3])/np.sum(C)\n","\n","    return sensitivity, specificity, accuracy\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"65xE2HVziG3B"},"outputs":[],"source":["\n","def save_masks(pred, names, output):\n","    \"\"\"\n","        Salva as máscaras geradas\n","\n","        Parameters\n","        ----------\n","        pred: array-like, float32\n","            Array contendo todas as máscaras preditas\n","        names: list, 'string'\n","            Lista de nomes dos arquivos das imagens\n","        output: string\n","            Nome do diretório onde as imagens serão salvas\n","            \n","    \"\"\"\n","    for i in range(pred.shape[0]):\n","        m = pred[i, :, :, 0]\n","        cv2.imwrite(output + names[i] + '.png', 255 * ((m - m.min())/(m.max() - m.min())))\n","    \n","\n","def generate_log(y_true, y_pred, names, output):\n","    \"\"\"\n","        Gera um log com os valores Dice, Sensibilidade, Especificidade e Acurácia para todas as imagens do conjunto de teste\n","\n","        Parameters\n","        ----------\n","        y_true: array-like, float32\n","            Mascara anotada manualmente (Ground-truth).\n","        y_pred: array-like, float32\n","            Mascara predita pelo modelo.\n","        names: list, string\n","            Lista com os nomes dos arquivos das imagens.\n","        output: string\n","            Caminho para o arquivo de saída.\n","        \n","        Returns\n","        -------\n","        Dice: float32\n","            Valor médio do IoU no intervalo [0, 1]\n","        Sensitivity: float32\n","            Valor médio da sensibilidade no intervalo [0, 1]\n","        Especificity: float32\n","            Valor médio da especificidade no intervalo [0, 1]\n","        Accuracy: float32\n","            Valor médio da acurácia no intervalo [0, 1]\n","    \"\"\"\n","    \n","    with open(output.split('.csv')[0] + '.csv', 'w') as f:\n","        f.write('NOME,IOU,SENSIBILIDADE,ESPECIFICIDADE,ACURACIA\\n')\n","        dice, sensibilidade, especificidade, acuracia = 0, 0, 0, 0\n","\n","        for i in range(y_pred.shape[0]):\n","            iou = dice_calc(y_true[i], y_pred[i])\n","            s, e, a = sensi_speci_accu(y_true[i], y_pred[i])\n","            \n","            dice += iou\n","            sensibilidade += s\n","            especificidade += e\n","            acuracia += a\n","\n","            f.write('{},{},{},{},{}\\n'.format(names[i], iou, s, e, a))\n","        \n","        return dice/y_pred.shape[0], sensibilidade/y_pred.shape[0], especificidade/y_pred.shape[0], acuracia/y_pred.shape[0]\n","\n","def save_statistics(filename, model_name, pre_processing_method, statistics):\n","\t(d, s, e, a) = statistics\n","\n","\twith open(filename, 'a') as f:\n","\t\tf.write('{},{},{},{},{},{}\\n'.format(model_name, pre_processing_method, d, s, e, a))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6J-or8upiIbE"},"outputs":[],"source":["def create_folder(path):\n","\tif not os.path.exists(path):\n","\t\t# shutil.rmtree(path)\n","\t    os.makedirs(path)\n"," \n","def prepare_folders(root, model_names, preprocessing_names):\n","    for model_name in model_names:\n","        current = root + '/' + model_name\n","\n","        create_folder(current)\n","        create_folder(current + '/logs')\n","        create_folder(current + '/masks')\n","        create_folder(current + '/weights')\n","\n","        for preprocessing_name in preprocessing_names:\n","            current_sub = current + '/masks/' + preprocessing_name\n","\n","            create_folder(current_sub)\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7_0ZXY97QAed"},"outputs":[],"source":["'''\n","'Linknet': Linknet,\n","'FPN': FPN,\n","'PSPNet': PSPNet\n","'''    \n","a = {\n","    'Unet': Unet \n","}\n","\n","'''\n","'vgg16', 'vgg19', \n","'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', \n","'seresnet18', 'seresnet34', 'seresnet50', 'seresnet101', 'seresnet152', \n","'seresnext50', 'seresnext101',\n","'resnext50', 'resnext101',\n","'senet154',\n","'densenet121', 'densenet169', 'densenet201',\n","'inceptionv3', 'inceptionresnetv2',\n","'mobilenet', 'mobilenetv2',\n","'efficientnetb0', 'efficientnetb1', 'efficientnetb2', 'efficientnetb3', 'efficientnetb4', 'efficientnetb5', 'efficientnetb6', 'efficientnetb7'\n","'''\n","\n","backbones = ['densenet169']\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"1ApBIbYlTF9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["TRAINING WITH MODEL Unet AND PREPROCESSING densenet169\n"]},{"name":"stderr","output_type":"stream","text":["2024-01-31 14:15:50.177767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:50.520898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:50.522278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:50.524224: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-01-31 14:15:50.525240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:50.526265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:50.527440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:51.070980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:51.071666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:51.072076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2024-01-31 14:15:51.072471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9429 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n","51877672/51877672 [==============================] - 48s 1us/step\n","Epoch 1/60\n"]},{"name":"stderr","output_type":"stream","text":["2024-01-31 14:17:01.852261: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n","2024-01-31 14:17:06.591547: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n","2024-01-31 14:17:11.719994: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"]},{"name":"stdout","output_type":"stream","text":["210/210 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.6338 - iou_score: 0.2186"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import segmentation_models as sm\n","\n","sm.set_framework('tf.keras')\n","\n","sm.framework()\n","\n","main_folder =  './bases/'#'/content/drive/MyDrive/chest/segment_gabriel/bases/' \n","main_models_folder =  './segm_models/'#'/content/drive/MyDrive/chest/segment_gabriel/segm_models'\n","X_train, y_train, X_val, y_val = load_data(main_folder + 'train_ALL_BASES_hm.pickle', main_folder + 'train_gt_ALL_BASES_hm.pickle',\n","                                           main_folder + 'test_ALL_BASES_hm.pickle', main_folder + 'test_gt_ALL_BASES_hm.pickle')\n","\n","X_test, y_test, X_test, y_test = load_data(main_folder + 'test_Chest_hm.pickle', main_folder + 'test_gt_Chest_hm.pickle',\n","                                           main_folder + 'test_Chest_hm.pickle', main_folder + 'test_gt_Chest_hm.pickle')\n","\n","with open('./evaluated.txt', 'r') as f: #/content/drive/MyDrive/chest/segment_gabriel/evaluated.txt'\n","    evaluated_models = names = [x.rstrip('\\n') for x in f.readlines()]\n","\n","with open('./names.txt', 'r') as f: #/content/drive/MyDrive/chest/segment_gabriel/names.txt\n","    names = [x.rstrip('\\n') for x in f.readlines()]\n","\n","prepare_folders(main_models_folder, [x[0] for x in a.items()], backbones)\n","\n","for (name, Model) in a.items():\n","    for BACKBONE in backbones:\n","        if not (name + '_' + BACKBONE) in evaluated_models:\n","            print('TRAINING WITH MODEL ' + name + ' AND PREPROCESSING ' + BACKBONE)\n","\n","            pre_processing = get_preprocessing(BACKBONE)\n","\n","            if name == 'PSPNet':\n","                [X_train, y_train, X_val, y_val] = resize_all([ X_train, y_train, X_val, y_val], (480, 480))\n","                [X_test, y_test] = resize_all([ X_test, y_test], (480, 480))\n","\n","            model = Model(BACKBONE, input_shape = (X_train.shape[1], X_train.shape[2], 3), classes = 1)\n","\n","            xt = pre_processing(X_train)\n","            xv = pre_processing(X_val)\n","            xtest = pre_processing(X_test)\n","            \n","                \n","            model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy', iou_score])\n","\n","            checkpoint = ModelCheckpoint('{}/{}/weights/{}_best_weights.hdf5'.format(main_models_folder, name, BACKBONE), monitor='val_iou_score', verbose=1, save_best_only=True,save_weights_only=True, mode='max')\n","            \n","            history = model.fit(\n","                x = xt,\n","                y = y_train,\n","                batch_size = 4,\n","                epochs = 60,\n","                callbacks = [checkpoint],\n","                validation_data = (xv, y_val),\n","            )\n","\n","            pred = model.predict(xtest)\n","            with open('{}/{}/pred_{}.pickle'.format(main_models_folder, name, BACKBONE), 'wb') as f:\n","                pickle.dump(pred, f)\n","\n","            statistics = generate_log(y_test, pred, names, '{}/{}/logs/{}.csv'.format(main_models_folder, name, BACKBONE))\n","            save_masks(pred, names, '{}/{}/masks/{}/'.format(main_models_folder, name, BACKBONE))\n","            save_statistics('{}/resultados'.format(main_models_folder), name, BACKBONE, statistics)\n","\n","            with open('evaluated.txt', 'a') as f:\n","                f.write(name + '_' + BACKBONE + '\\n')\n"]},{"cell_type":"markdown","metadata":{"id":"8MxSwubxzJ4P"},"source":["#Isolando os testes\n","\n","Aqui com a mesma base de homologação, usando o melhor modelo obtido"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z74sGwxCuHIx"},"outputs":[],"source":["from keras.models import load_model, Model\n","\n","#predict\n","main_folder = '/content/drive/MyDrive/chest/segment_gabriel/bases/'\n","main_models_folder = '/content/drive/MyDrive/chest/segment_gabriel/segm_models'\n","X_test, y_test, X_test, y_test = load_data(main_folder + 'test_Chest_hm.pickle', main_folder + 'test_gt_Chest_hm.pickle',\n","                                           main_folder + 'test_Chest_hm.pickle', main_folder + 'test_gt_Chest_hm.pickle')\n","with open('/content/drive/MyDrive/chest/segment_gabriel/names.txt', 'r') as f:\n","    names = [x.rstrip('\\n') for x in f.readlines()]\n","    \n","BACKBONE = 'densenet169'\n","name = 'Unet'\n","\n","model = Unet(BACKBONE, input_shape = (X_train.shape[1], X_train.shape[2], 3), classes = 1)\n","model.load_weights('/content/drive/MyDrive/chest/segment_gabriel/best_weights_best_results/best_weightsUnet_densenet169_best_weights.hdf5')\n","\n","pred = model.predict(xtest)\n","with open('{}/{}/pred_{}.pickle'.format(main_models_folder, name, BACKBONE), 'wb') as f:\n","    pickle.dump(pred, f)\n","\n","statistics = generate_log(y_test, pred, names, '{}/{}/logs/{}.csv'.format(main_models_folder, name, BACKBONE))\n","save_masks(pred, names, '{}/{}/masks/{}/'.format(main_models_folder, name, BACKBONE))\n","save_statistics('{}/resultados'.format(main_models_folder), name, BACKBONE, statistics)\n","\n","with open('evaluated.txt', 'a') as f:\n","    f.write(name + '_' + BACKBONE + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"izkAg7QPzRZg"},"source":["#Montando a base completa da Chest X-Ray\n","Pegando a base inteira e obtendo a segmentação com o melhor modelo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109997,"status":"ok","timestamp":1624383994705,"user":{"displayName":"Geraldo Braz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtXqi3trku-rIuoH0xOWyRiWTOHzjF-3aMiSoqK0CZug5CIQfFtp6j1Cm-cF40EeBEIFwQFaLAJ8BPUps0xRoqFhDQ8cOVsNv7LIUChnyydRpTwpl2HlkpsZcAIKeuUfbohPt9Pi_5xok3cbvqGNAOARrAlJelD-bU2J1ZghmMFUykKyUgDXN8jTdApXHDT7IeXAZIjrOQGwYLLaOwQ94ueWkjc_nrF00_zmFdJ47SMHg7Y0nkHszZHr8fOFyTzecDyvDh8lRZ76r-pm1Tws-1xq4ei3YoRrhy2HbvzOL2R3o5i1ApWPL6Yvkc1cj_vsIWgWD7zJS-0H-tfye90BSuM_u-wnI2sqW9TyJ-xn6X1FIVwZXQP6PHOnkl4aZIVnNAnv8i7-rvQcePg_F5ipLrnreY0YcuDGwNts2eRkQWLfWBo7UH3Gbp_WJ3MUT0FMdF3zAXrFJBWBobo8lKycnXHOBf1Hrik_wx0k_omC-lRXEsz7ST-oy_BBT9Ev_zB3BAv8L-BgJp4NvVPkPzSANL0pyoBkMGliA90O1RMiKLj1mUtidyP0XsR8xgky0iFwCCtLgF9yAceqV7ibGpD3EY-gS4AayTFFdAqnZGbaNofg6sNN2ZDuHlXav4_3pCjNC_zvp5iPTvfBRfoKx0_qaDaabQBpw8ZemqUgLMf_aJ6whbZfxsP1Zu9Q6D8Hyaoht6vP7ZS1fXOR-Hj0kRGUCWoL4Bt2brXeLoz85LvcXW6VCWxdf9-n9_JPv4STvk1SV2oQ=s64","userId":"07309379484309223386"},"user_tz":180},"id":"2caxrTIczQjQ","outputId":"c944bde6-299c-47ef-f98d-18965ed179b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Downloading chest-xray-pneumonia.zip to /content\n","100% 2.29G/2.29G [00:32<00:00, 30.0MB/s]\n","100% 2.29G/2.29G [00:32<00:00, 75.1MB/s]\n"]}],"source":["!pip install kaggle\n","import os\n","os.environ['KAGGLE_USERNAME'] = \"geraldobraz\"\n","os.environ['KAGGLE_KEY'] = \"fbca5960f1451ba427d6a9397840aa67\"\n","!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n","!unzip -q chest-xray-pneumonia.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GbF-BppH4ows"},"outputs":[],"source":["!rm -rf chest_xray_seg \n","!mkdir chest_xray_seg\n","!mkdir chest_xray_seg/train\n","!mkdir chest_xray_seg/test\n","!mkdir chest_xray_seg/val\n","!mkdir chest_xray_seg/train/NORMAL\n","!mkdir chest_xray_seg/train/PNEUMONIA\n","!mkdir chest_xray_seg/val/NORMAL\n","!mkdir chest_xray_seg/val/PNEUMONIA\n","!mkdir chest_xray_seg/test/NORMAL\n","!mkdir chest_xray_seg/test/PNEUMONIA\n","\n","!rm -rf chest_xray_mask\n","!mkdir chest_xray_mask\n","!mkdir chest_xray_mask/train\n","!mkdir chest_xray_mask/test\n","!mkdir chest_xray_mask/val\n","!mkdir chest_xray_mask/train/NORMAL\n","!mkdir chest_xray_mask/train/PNEUMONIA\n","!mkdir chest_xray_mask/val/NORMAL\n","!mkdir chest_xray_mask/val/PNEUMONIA\n","!mkdir chest_xray_mask/test/NORMAL\n","!mkdir chest_xray_mask/test/PNEUMONIA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"elapsed":603990,"status":"ok","timestamp":1624387852815,"user":{"displayName":"Geraldo Braz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtXqi3trku-rIuoH0xOWyRiWTOHzjF-3aMiSoqK0CZug5CIQfFtp6j1Cm-cF40EeBEIFwQFaLAJ8BPUps0xRoqFhDQ8cOVsNv7LIUChnyydRpTwpl2HlkpsZcAIKeuUfbohPt9Pi_5xok3cbvqGNAOARrAlJelD-bU2J1ZghmMFUykKyUgDXN8jTdApXHDT7IeXAZIjrOQGwYLLaOwQ94ueWkjc_nrF00_zmFdJ47SMHg7Y0nkHszZHr8fOFyTzecDyvDh8lRZ76r-pm1Tws-1xq4ei3YoRrhy2HbvzOL2R3o5i1ApWPL6Yvkc1cj_vsIWgWD7zJS-0H-tfye90BSuM_u-wnI2sqW9TyJ-xn6X1FIVwZXQP6PHOnkl4aZIVnNAnv8i7-rvQcePg_F5ipLrnreY0YcuDGwNts2eRkQWLfWBo7UH3Gbp_WJ3MUT0FMdF3zAXrFJBWBobo8lKycnXHOBf1Hrik_wx0k_omC-lRXEsz7ST-oy_BBT9Ev_zB3BAv8L-BgJp4NvVPkPzSANL0pyoBkMGliA90O1RMiKLj1mUtidyP0XsR8xgky0iFwCCtLgF9yAceqV7ibGpD3EY-gS4AayTFFdAqnZGbaNofg6sNN2ZDuHlXav4_3pCjNC_zvp5iPTvfBRfoKx0_qaDaabQBpw8ZemqUgLMf_aJ6whbZfxsP1Zu9Q6D8Hyaoht6vP7ZS1fXOR-Hj0kRGUCWoL4Bt2brXeLoz85LvcXW6VCWxdf9-n9_JPv4STvk1SV2oQ=s64","userId":"07309379484309223386"},"user_tz":180},"id":"3nKKTM4k05Zj","outputId":"b6668d48-8eef-436c-93ec-9c2236d1a079"},"outputs":[{"name":"stdout","output_type":"stream","text":["['NORMAL', 'PNEUMONIA']\n","/content/chest_xray/train/NORMAL/*.jpeg\n","/content/chest_xray/train/PNEUMONIA/*.jpeg\n","['NORMAL', 'PNEUMONIA']\n","/content/chest_xray/val/NORMAL/*.jpeg\n","/content/chest_xray/val/PNEUMONIA/*.jpeg\n","['NORMAL', 'PNEUMONIA']\n","/content/chest_xray/test/NORMAL/*.jpeg\n","/content/chest_xray/test/PNEUMONIA/*.jpeg\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nX_train, y_train = extract('train/')\\nprint(X_train.shape)\\nprint(y_train.shape)\\n\\nX_val, y_val = extract('val/')\\nprint(X_val.shape)\\nprint(y_val.shape)\\n\\nX_test, y_test = extract('test/')\\nprint(X_test.shape)\\nprint(y_test.shape)\\n\""]},"execution_count":39,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["#gerando as mascaras\n","import os\n","import glob\n","import cv2\n","import numpy as np\n","import segmentation_models as sm\n","from segmentation_models import *\n","from segmentation_models.metrics import iou_score\n","\n","sm.set_framework('tf.keras')\n","sm.framework()\n","\n","#parametros globais\n","base_folder = '/content/chest_xray/'\n","image_format = '.jpeg'\n","\n","BACKBONE = 'densenet169'\n","name = 'Unet'\n","\n","model = Unet(BACKBONE, input_shape = (X_train.shape[1], X_train.shape[2], 3), classes = 1)\n","model.load_weights('/content/drive/MyDrive/chest/segment_gabriel/best_weights_best_results/best_weightsUnet_densenet169_best_weights.hdf5')\n","pre_processing = get_preprocessing(BACKBONE)\n","\n","def get_folders(data_base):\n","  data_folders = []\n","  for name in os.listdir(data_base):\n","    if(os.path.isdir(data_base + name)):\n","      data_folders.append(name)\n","  print(data_folders)\n","\n","  return data_folders\n","\n","def extract(spec):\n","\tclasses_folders = get_folders(base_folder + spec)\n","\n","\tdata = []\n","\tlabels = []\n","\tfor f in classes_folders:\n","\t\tprint(base_folder + spec + f + \"/*\" + image_format)\n","\t\tdataset = glob.glob(base_folder + spec + f + \"/*\" + image_format)\n","\t\tfor arq in dataset:\t\t\t\n","\t\t\tim = cv2.imread(arq)\n","\t\t\tim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","\t\t\tim = cv2.resize(im, (512,512))\n","\t\t\tim = np.reshape(im, (1, 512, 512, 3))\n","\t\t\t#pre_process do backbone\n","\t\t\tim = pre_processing(im)\n","\t\t\t#predição\n","\t\t\tpred = model.predict(im)\n","\n","\t\t\tm = pred[0, :, :, 0]\n","\t\t\tm =  255 * ((m - m.min())/(m.max() - m.min()))\n","\t\t\tm = m.astype('uint8')\n","\n","\t\t\tf = im[0, :, :, 0]\n","\t\t\tf =  255 * ((f - f.min())/(f.max() - f.min()))\n","\t\t\tf = f.astype('uint8')\n","\n","\t\t\tfinal = cv2.bitwise_and(f, f, mask=m)\n","\n","\t\t\t#salvando a mascara\n","\t\t\tcv2.imwrite(arq.replace(\"chest_xray\", \"chest_xray_mask\") + '.png', m)\n","\t\t\t#salvando a imagem\n","\t\t\tcv2.imwrite(arq.replace(\"chest_xray\", \"chest_xray_seg\"), final)\n","\n","\t\t\t#data.append(im)\n","\t\t\t#labels.append(f)\n","\t#return np.asarray(data), np.asarray(labels)\n","\n","extract('train/')\n","extract('val/')\n","extract('test/')\n","'''\n","X_train, y_train = extract('train/')\n","print(X_train.shape)\n","print(y_train.shape)\n","\n","X_val, y_val = extract('val/')\n","print(X_val.shape)\n","print(y_val.shape)\n","\n","X_test, y_test = extract('test/')\n","print(X_test.shape)\n","print(y_test.shape)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QN5uRq2W8lCm"},"outputs":[],"source":["!tar -czf chest_xray_mask.tar.gz chest_xray_mask/\n","!tar -czf chest_xray_seg.tar.gz chest_xray_seg/\n","!mv *.tar.gz /content/drive/MyDrive/chest/segment_gabriel"]},{"cell_type":"markdown","metadata":{"id":"bqo2PGcXFfxL"},"source":["#Montando a base completa da Covid\n","Pegando a base inteira e obtendo a segmentação com o melhor modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17518,"status":"ok","timestamp":1624388316524,"user":{"displayName":"Geraldo Braz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtXqi3trku-rIuoH0xOWyRiWTOHzjF-3aMiSoqK0CZug5CIQfFtp6j1Cm-cF40EeBEIFwQFaLAJ8BPUps0xRoqFhDQ8cOVsNv7LIUChnyydRpTwpl2HlkpsZcAIKeuUfbohPt9Pi_5xok3cbvqGNAOARrAlJelD-bU2J1ZghmMFUykKyUgDXN8jTdApXHDT7IeXAZIjrOQGwYLLaOwQ94ueWkjc_nrF00_zmFdJ47SMHg7Y0nkHszZHr8fOFyTzecDyvDh8lRZ76r-pm1Tws-1xq4ei3YoRrhy2HbvzOL2R3o5i1ApWPL6Yvkc1cj_vsIWgWD7zJS-0H-tfye90BSuM_u-wnI2sqW9TyJ-xn6X1FIVwZXQP6PHOnkl4aZIVnNAnv8i7-rvQcePg_F5ipLrnreY0YcuDGwNts2eRkQWLfWBo7UH3Gbp_WJ3MUT0FMdF3zAXrFJBWBobo8lKycnXHOBf1Hrik_wx0k_omC-lRXEsz7ST-oy_BBT9Ev_zB3BAv8L-BgJp4NvVPkPzSANL0pyoBkMGliA90O1RMiKLj1mUtidyP0XsR8xgky0iFwCCtLgF9yAceqV7ibGpD3EY-gS4AayTFFdAqnZGbaNofg6sNN2ZDuHlXav4_3pCjNC_zvp5iPTvfBRfoKx0_qaDaabQBpw8ZemqUgLMf_aJ6whbZfxsP1Zu9Q6D8Hyaoht6vP7ZS1fXOR-Hj0kRGUCWoL4Bt2brXeLoz85LvcXW6VCWxdf9-n9_JPv4STvk1SV2oQ=s64","userId":"07309379484309223386"},"user_tz":180},"id":"XJGki2oPFiRo","outputId":"053d7b38-0e41-417f-df47-5b0cd48113e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Downloading covid19-radiography-database.zip to /content\n"," 98% 729M/745M [00:06<00:00, 120MB/s]\n","100% 745M/745M [00:06<00:00, 123MB/s]\n","mv: cannot stat 'COVID-19 Radiography Database': No such file or directory\n"]}],"source":["!pip install kaggle\n","import os\n","os.environ['KAGGLE_USERNAME'] = \"geraldobraz\"\n","os.environ['KAGGLE_KEY'] = \"fbca5960f1451ba427d6a9397840aa67\"\n","!kaggle datasets download -d tawsifurrahman/covid19-radiography-database\n","!unzip -q covid19-radiography-database.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2397,"status":"ok","timestamp":1624389165110,"user":{"displayName":"Geraldo Braz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtXqi3trku-rIuoH0xOWyRiWTOHzjF-3aMiSoqK0CZug5CIQfFtp6j1Cm-cF40EeBEIFwQFaLAJ8BPUps0xRoqFhDQ8cOVsNv7LIUChnyydRpTwpl2HlkpsZcAIKeuUfbohPt9Pi_5xok3cbvqGNAOARrAlJelD-bU2J1ZghmMFUykKyUgDXN8jTdApXHDT7IeXAZIjrOQGwYLLaOwQ94ueWkjc_nrF00_zmFdJ47SMHg7Y0nkHszZHr8fOFyTzecDyvDh8lRZ76r-pm1Tws-1xq4ei3YoRrhy2HbvzOL2R3o5i1ApWPL6Yvkc1cj_vsIWgWD7zJS-0H-tfye90BSuM_u-wnI2sqW9TyJ-xn6X1FIVwZXQP6PHOnkl4aZIVnNAnv8i7-rvQcePg_F5ipLrnreY0YcuDGwNts2eRkQWLfWBo7UH3Gbp_WJ3MUT0FMdF3zAXrFJBWBobo8lKycnXHOBf1Hrik_wx0k_omC-lRXEsz7ST-oy_BBT9Ev_zB3BAv8L-BgJp4NvVPkPzSANL0pyoBkMGliA90O1RMiKLj1mUtidyP0XsR8xgky0iFwCCtLgF9yAceqV7ibGpD3EY-gS4AayTFFdAqnZGbaNofg6sNN2ZDuHlXav4_3pCjNC_zvp5iPTvfBRfoKx0_qaDaabQBpw8ZemqUgLMf_aJ6whbZfxsP1Zu9Q6D8Hyaoht6vP7ZS1fXOR-Hj0kRGUCWoL4Bt2brXeLoz85LvcXW6VCWxdf9-n9_JPv4STvk1SV2oQ=s64","userId":"07309379484309223386"},"user_tz":180},"id":"i3_gX5fXG6UY","outputId":"9f7ac85d-ba1d-4267-f3f9-8b5e29d33bf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["mv: cannot stat 'COVID-19_Radiography_Dataset/Viral Pneumonia': No such file or directory\n"]}],"source":["!mv COVID-19_Radiography_Dataset/Viral\\ Pneumonia COVID-19_Radiography_Dataset/Viral\n","!rm -rf COVID-19_Radiography_Dataset_mask\n","!mkdir COVID-19_Radiography_Dataset_mask\n","!mkdir COVID-19_Radiography_Dataset_mask/COVID\n","!mkdir COVID-19_Radiography_Dataset_mask/Lung_Opacity\n","!mkdir COVID-19_Radiography_Dataset_mask/Normal\n","!mkdir COVID-19_Radiography_Dataset_mask/Viral\n","\n","!rm -rf COVID-19_Radiography_Dataset_seg\n","!mkdir COVID-19_Radiography_Dataset_seg\n","!mkdir COVID-19_Radiography_Dataset_seg/COVID\n","!mkdir COVID-19_Radiography_Dataset_seg/Lung_Opacity\n","!mkdir COVID-19_Radiography_Dataset_seg/Normal\n","!mkdir COVID-19_Radiography_Dataset_seg/Viral"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"elapsed":1850255,"status":"ok","timestamp":1624391279358,"user":{"displayName":"Geraldo Braz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtXqi3trku-rIuoH0xOWyRiWTOHzjF-3aMiSoqK0CZug5CIQfFtp6j1Cm-cF40EeBEIFwQFaLAJ8BPUps0xRoqFhDQ8cOVsNv7LIUChnyydRpTwpl2HlkpsZcAIKeuUfbohPt9Pi_5xok3cbvqGNAOARrAlJelD-bU2J1ZghmMFUykKyUgDXN8jTdApXHDT7IeXAZIjrOQGwYLLaOwQ94ueWkjc_nrF00_zmFdJ47SMHg7Y0nkHszZHr8fOFyTzecDyvDh8lRZ76r-pm1Tws-1xq4ei3YoRrhy2HbvzOL2R3o5i1ApWPL6Yvkc1cj_vsIWgWD7zJS-0H-tfye90BSuM_u-wnI2sqW9TyJ-xn6X1FIVwZXQP6PHOnkl4aZIVnNAnv8i7-rvQcePg_F5ipLrnreY0YcuDGwNts2eRkQWLfWBo7UH3Gbp_WJ3MUT0FMdF3zAXrFJBWBobo8lKycnXHOBf1Hrik_wx0k_omC-lRXEsz7ST-oy_BBT9Ev_zB3BAv8L-BgJp4NvVPkPzSANL0pyoBkMGliA90O1RMiKLj1mUtidyP0XsR8xgky0iFwCCtLgF9yAceqV7ibGpD3EY-gS4AayTFFdAqnZGbaNofg6sNN2ZDuHlXav4_3pCjNC_zvp5iPTvfBRfoKx0_qaDaabQBpw8ZemqUgLMf_aJ6whbZfxsP1Zu9Q6D8Hyaoht6vP7ZS1fXOR-Hj0kRGUCWoL4Bt2brXeLoz85LvcXW6VCWxdf9-n9_JPv4STvk1SV2oQ=s64","userId":"07309379484309223386"},"user_tz":180},"id":"jDcFgJohGqR-","outputId":"f73be405-b34d-43d7-c186-3d48497e911e"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Lung_Opacity', 'Viral', 'Normal', 'COVID']\n","/content/COVID-19_Radiography_Dataset/Lung_Opacity/*.png\n","/content/COVID-19_Radiography_Dataset/Viral/*.png\n","/content/COVID-19_Radiography_Dataset/Normal/*.png\n","/content/COVID-19_Radiography_Dataset/COVID/*.png\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nX_train, y_train = extract('train/')\\nprint(X_train.shape)\\nprint(y_train.shape)\\n\\nX_val, y_val = extract('val/')\\nprint(X_val.shape)\\nprint(y_val.shape)\\n\\nX_test, y_test = extract('test/')\\nprint(X_test.shape)\\nprint(y_test.shape)\\n\""]},"execution_count":55,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["#gerando as mascaras\n","import os\n","import glob\n","import cv2\n","import numpy as np\n","import segmentation_models as sm\n","from segmentation_models import *\n","from segmentation_models.metrics import iou_score\n","\n","sm.set_framework('tf.keras')\n","sm.framework()\n","\n","#parametros globais\n","base_folder = '/content/COVID-19_Radiography_Dataset/'\n","image_format = '.png'\n","\n","BACKBONE = 'densenet169'\n","name = 'Unet'\n","\n","model = Unet(BACKBONE, input_shape = (X_train.shape[1], X_train.shape[2], 3), classes = 1)\n","model.load_weights('/content/drive/MyDrive/chest/segment_gabriel/best_weights_best_results/best_weightsUnet_densenet169_best_weights.hdf5')\n","pre_processing = get_preprocessing(BACKBONE)\n","\n","def get_folders(data_base):\n","  data_folders = []\n","  for name in os.listdir(data_base):\n","    if(os.path.isdir(data_base + name)):\n","      data_folders.append(name)\n","  print(data_folders)\n","\n","  return data_folders\n","\n","def extract(spec):\n","\tclasses_folders = get_folders(base_folder + spec)\n","\n","\tdata = []\n","\tlabels = []\n","\tfor f in classes_folders:\n","\t\tprint(base_folder + spec + f + \"/*\" + image_format)\n","\t\tdataset = glob.glob(base_folder + spec + f + \"/*\" + image_format)\n","\t\tfor arq in dataset:\t\t\t\n","\t\t\tim = cv2.imread(arq)\n","\t\t\tim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","\t\t\tim = cv2.resize(im, (512,512))\n","\t\t\tim = np.reshape(im, (1, 512, 512, 3))\n","\t\t\t#pre_process do backbone\n","\t\t\tim = pre_processing(im)\n","\t\t\t#predição\n","\t\t\tpred = model.predict(im)\n","\n","\t\t\tm = pred[0, :, :, 0]\n","\t\t\tm =  255 * ((m - m.min())/(m.max() - m.min()))\n","\t\t\tm = m.astype('uint8')\n","\n","\t\t\tf = im[0, :, :, 0]\n","\t\t\tf =  255 * ((f - f.min())/(f.max() - f.min()))\n","\t\t\tf = f.astype('uint8')\n","\n","\t\t\tfinal = cv2.bitwise_and(f, f, mask=m)\n","\n","\t\t\t#salvando a mascara\n","\t\t\tcv2.imwrite(arq.replace(\"COVID-19_Radiography_Dataset\", \"COVID-19_Radiography_Dataset_mask\") + '.png', m)\n","\t\t\t#salvando a imagem\n","\t\t\tcv2.imwrite(arq.replace(\"COVID-19_Radiography_Dataset\", \"COVID-19_Radiography_Dataset_seg\"), final)\n","\n","\t\t\t#data.append(im)\n","\t\t\t#labels.append(f)\n","\t#return np.asarray(data), np.asarray(labels)\n","\n","extract('')\n","\n","\n","'''\n","X_train, y_train = extract('train/')\n","print(X_train.shape)\n","print(y_train.shape)\n","\n","X_val, y_val = extract('val/')\n","print(X_val.shape)\n","print(y_val.shape)\n","\n","X_test, y_test = extract('test/')\n","print(X_test.shape)\n","print(y_test.shape)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NWxCoDRKRA7"},"outputs":[],"source":["!tar -czf COVID-19_Radiography_Dataset_mask.tar.gz COVID-19_Radiography_Dataset_mask/\n","!tar -czf COVID-19_Radiography_Dataset_seg.tar.gz COVID-19_Radiography_Dataset_seg/\n","!mv *.tar.gz /content/drive/MyDrive/chest/segment_gabriel"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"teste_segmentation_models_3.ipynb","provenance":[{"file_id":"1nWCGJve3EmJX6QwNiw29ivfrp67N_gPX","timestamp":1624582282027}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
